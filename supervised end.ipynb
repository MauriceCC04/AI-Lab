{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "First load all data from the files into individual dataframes (and import necessary libraries)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": ""
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#laptop\n",
    "#df_DropSeq_MCF7 = pd.read_csv(\"C:\\\\Users\\\\camer\\\\Desktop\\\\class stuff\\\\Semester 4\\\\ai lab\\\\DropSeq\\\\MCF7_Filtered_Normalised_3000_Data_train.txt\", delimiter=\"\\ \", engine='python', index_col=0)\n",
    "#desktop\n",
    "#C:\\Users\\Cameron\\Desktop\\AILab24\\DropSeq\n",
    "MCF_DropSeq = pd.read_csv(\"C:\\\\Users\\\\Cameron\\\\Desktop\\\\AILab24\\\\DropSeq\\\\MCF7_Filtered_Normalised_3000_Data_train.txt\",\n",
    "                  delimiter=\"\\ \", engine='python', index_col=0)\n",
    "MCF_DropSeq = MCF_DropSeq.T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#laptop\n",
    "#df = pd.read_csv(\"C:\\\\Users\\\\camer\\\\Desktop\\\\class stuff\\\\Semester 4\\\\ai lab\\\\DropSeq\\\\HCC1806_Filtered_Normalised_3000_Data_train.txt\", delimiter=\"\\ \", engine='python', index_col=0)\n",
    "#desktop\n",
    "#C:\\Users\\Cameron\\Desktop\\AILab24\\DropSeq\n",
    "HCC_DropSeq = pd.read_csv(\"C:\\\\Users\\\\Cameron\\\\Desktop\\\\AILab24\\\\DropSeq\\\\HCC1806_Filtered_Normalised_3000_Data_train.txt\", delimiter=\"\\ \", engine='python', index_col=0)\n",
    "HCC_DropSeq = HCC_DropSeq.T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MCF_SS = pd.read_csv(\"C:\\\\Users\\\\camer\\\\Desktop\\\\class stuff\\\\Semester 4\\\\ai lab\\\\SmartSeq\\\\MCF7_SmartS_Filtered_Normalised_3000_Data_train.txt\", delimiter=\"\\ \",engine='python',index_col=0)\n",
    "HCC_SS = pd.read_csv(\"C:\\\\Users\\\\camer\\\\Desktop\\\\class stuff\\\\Semester 4\\\\ai lab\\\\SmartSeq\\\\HCC1806_SmartS_Filtered_Normalised_3000_Data_train.txt\", delimiter=\"\\ \",engine='python',index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#function to add new 'Oxia' row to the data frame\n",
    "#1 is Normoxia, 0 is Hypoxia\n",
    "def oxia(df):\n",
    "    new_row = {col: None for col in df.columns}\n",
    "    for col in df.columns:\n",
    "        if '_Normoxia' in col:\n",
    "            new_row[col] = 1\n",
    "        elif '_Hypoxia' in col:\n",
    "            new_row[col] = 0\n",
    "    df = pd.concat([df, pd.DataFrame(new_row, index=['oxia'])])\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#add all files to a single dictionary which will be worked on\n",
    "data = {'MCF_DropSeq': MCF_DropSeq, 'HCC_DropSeq': HCC_DropSeq, 'MCF_SS': MCF_SS, 'HCC_SS': HCC_SS}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#apply oxia function to all dataframes\n",
    "for key in data:\n",
    "    data[key] = oxia(data[key])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#function to split the data into X and y\n",
    "def split_data(df):\n",
    "    X = df.drop('oxia', axis=0)\n",
    "    y = df.loc['oxia']\n",
    "    return (X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#split all dataframes into X and y\n",
    "for key in data:\n",
    "    data[key] = split_data(data[key])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#function to split the data into training and testing data\n",
    "def split_train_test(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#split all dataframes into training and testing data\n",
    "for key in data:\n",
    "    data[key] = split_train_test(data[key][0], data[key][1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dictionary of models:\n",
    "models = {'Logistic Regression': LogisticRegression(), 'KNN': KNeighborsClassifier(), 'Random Forest': RandomForestClassifier(), 'SVM': SVC(), 'Neural Network': MLPClassifier(), 'Linear Regression': LinearRegression()}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#now iterate through all the models and all the data\n",
    "# print(\"Confusion Matrix: \", confusion_matrix(y_test_MCF, y_pred_MCF))\n",
    "#     print(classification_report(y_test_loop, y_pred))\n",
    "for key in data:\n",
    "    for model in models:\n",
    "        models[model].fit(data[key][0], data[key][2])\n",
    "        y_pred = models[model].predict(data[key][1])\n",
    "        print(model, key, accuracy_score(data[key][3], y_pred), classification_report(data[key][3], y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#now do this with a grid search to find optimal parameters\n",
    "params = {'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print best parameters\n",
    "for key in data:\n",
    "    for model in models:\n",
    "        grid = GridSearchCV(models[model], params, cv=5)\n",
    "        grid.fit(data[key][0], data[key][2])\n",
    "        y_pred = grid.predict(data[key][1])\n",
    "        print(model, key, accuracy_score(data[key][3], y_pred), classification_report(data[key][3], y_pred))\n",
    "        print(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
